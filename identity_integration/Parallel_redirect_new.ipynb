{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import networkx as nx\n",
    "import csv\n",
    "import requests\n",
    "from requests.exceptions import Timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constants and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMEAS = \"http://www.w3.org/2002/07/owl#sameAs\"\n",
    "MY_REDIRECT = \"https://krr.triply.cc/krr/metalink/def/redirectedTo\"\n",
    "NOTFOUND = 1\n",
    "NOREDIRECT = 2\n",
    "ERROR = 3\n",
    "TIMEOUT = 4\n",
    "REDIRECT = 5\n",
    "STANDARD_TIMEOUT = (0.01, 0.05)\n",
    "RETRY_TIMEOUT = (0.5, 2.5)\n",
    "FINAL_TRY_TIMEOUT = (1, 5)\n",
    "\n",
    "files = [] # locations of the graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find redirects\\\n",
    "input: IRI, timeout (tuple)\\\n",
    "output: NOTFOUND etc, and the URLS it got redirected to (optional)\\\n",
    "go to IRI and if response is 404 return NOTFOUND, None\\\n",
    "if response url is IRI return NOREDIRECT, None\\\n",
    "else return REDIRECT, and all the urls it redirected to\\\n",
    "if there is no response url return NOREDIRECT, None\\\n",
    "return TIMEOUT, None in case of time out\\\n",
    "return ERROR, none in case of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_redirects(iri, timeout):\n",
    "    try:\n",
    "        collect_urls = []\n",
    "        response = requests.get(iri, timeout=timeout, allow_redirects=True)\n",
    "\n",
    "        if response.status_code == 404:\n",
    "            return NOTFOUND, None\n",
    "        if response.history:\n",
    "            if response.url == iri: # check if reponse.url encodes iri\n",
    "                return NOREDIRECT, None\n",
    "            else:\n",
    "                for resp in response.history: # why loop through history here but not at respoonse.url == iri\n",
    "                    collect_urls.append(resp.url)\n",
    "                collect_urls.append(response.url) # check for duplicates\n",
    "                return REDIRECT, collect_urls\n",
    "    except Timeout:\n",
    "        return TIMEOUT, None\n",
    "    except:\n",
    "        return ERROR, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load entities\\\n",
    "input: path to the graph (CSV)\\\n",
    "output: set with all subjects and objects in the graph\\\n",
    "load entities from a csv, then loop through all subjects and objects and put them in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_entities(path_to_input_graph):\n",
    "    input_graph_data = pd.read_csv(path_to_input_graph)\n",
    "\n",
    "    sources = input_graph_data['SUBJECT']\n",
    "    targets = input_graph_data['OBJECT']\n",
    "    edge_data = zip(sources, targets)\n",
    "\n",
    "    entities = set()\n",
    "    for (s,t) in edge_data:\n",
    "        entities.add(s)\n",
    "        entities.add(t)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO use Pool to get multiple IRI's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import pool\n",
    "for file in files:\n",
    "    print(file)\n",
    "    start = time.time()\n",
    "\n",
    "    redi_graph = nx.DiGraph()\n",
    "\n",
    "    entities_to_test = load_entities(file)\n",
    "    print(f\"There are {len(entities_to_test)} entities in the graph\")\n",
    "    \n",
    "    timeout_entities = set()\n",
    "    original_entities = entities_to_test.copy()\n",
    "    redirect_result = {}\n",
    "\n",
    "    for e in entities_to_test:\n",
    "        redirect_result[e] = None\n",
    "    \n",
    "    while len(entities_to_test) != 0:\n",
    "        collect_new_entities_to_test = set()\n",
    "        with pool(10) as pool:\n",
    "            for e in pool.imap_unordered(find_redirects, entities_to_test):\n",
    "                pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4856f06944c4b3c813e85b7a0fddc34ad1a42525098d1066ef7be97a192d967"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
